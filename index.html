<!doctype html>
<!DOCTYPE html>
<html>
<head>
  <title>WebCodec MP4 frame extration demo</title>
  <meta http-equiv="origin-trial" content="ArdlZia9G23wi6S2x/vVoTla5x9r1wtreSPqhUq36tpGH7HRmAkPgpBnpkfePFeClDJDzzYAhtDPoI5hJioArAYAAABjeyJvcmlnaW4iOiJodHRwczovL3czYy5naXRodWIuaW86NDQzIiwiZmVhdHVyZSI6IldlYkNvZGVjcyIsImV4cGlyeSI6MTYzODQwMzE5OSwiaXNTdWJkb21haW4iOnRydWV9" />
</head>
<body>
  <p>
    This demo extracts all frames from an MP4 file and renders them to a canvas as fast as possible. It uses <a href="https://github.com/gpac/mp4box.js/">mp4box.js</a> to parse and demux the file.
  </p>
  <div>
  <div id=controls>
    <p id=loading>Loading...</p>
    <button disabled=true>Play</button>
    <label for=volume>Volume</label>
    <input id=volume type=range value=0.8 min=0 max=1.0 step=0.01></input>
  </div>
</div>
  <canvas width=1280 height=720></canvas>
</body>

<script type="module">
    import { MyAudioContext } from "./audiocontext.js";
  window.$ = document.querySelector.bind(document);
  var demuxDecodeWorker;

  var canvas = document.querySelector("canvas");
  var offscreen = canvas.transferControlToOffscreen();
  document.body.appendChild(canvas);

  var frameCount = 0;
  var startTime;

  demuxDecodeWorker = new Worker("./demux_decode_worker.js");
  demuxDecodeWorker.postMessage({command: 'initialize',
                                    canvas: offscreen},
                                    {transfer:[offscreen]});


  let initResolver = null;
  let initDone = new Promise(resolver => (initResolver = resolver));  
  let myAudioContext = new MyAudioContext();
  demuxDecodeWorker.addEventListener('message', (e) => {
    console.assert(e.data.command == 'initialize-done');
    myAudioContext.initialize();
    // audioController.initialize(e.data.sampleRate, e.data.channelCount,
    //                     e.data.sharedArrayBuffer);
    initResolver();
    initResolver = null;
  });
  await initDone;

  let playButton = $('button');
  let loadingElement = $('#loading');
  playButton.disabled = false;
  loadingElement.innerText = 'Ready! Click play.'


  //播放按钮点击后触发的事件
playButton.onclick = () => {
  if (playButton.innerText == "Play") {
    console.log("playback start");

    // Audio can only start in reaction to a user-gesture.
    //必须要在用户事件触发之下，audiocontroller才能够执行
    myAudioContext.play().then(() => console.log('playback started'));
    //mediaworker执行操作
    demuxDecodeWorker.postMessage({
        command: 'play',
        mediaTimeSecs: myAudioContext.getMediaTimeInSeconds(),
        mediaTimeCapturedAtHighResTimestamp:
            performance.now() + performance.timeOrigin
    });

    //本地方法
    sendMediaTimeUpdates(true);

    playButton.innerText = "Pause";

  } else {
    console.log("playback pause");
    // Resolves when audio has effectively stopped, this can take some time if
    // using bluetooth, for example.
    //解决音频停止时的问题，
    myAudioContext.pause().then(() => { console.log("playback paused");
      //等待中止工作线程，上下文挂起，这是为了确保在播放音频的时候填充audio buffer
      // Wait to pause worker until context suspended to ensure we continue
      // filling audio buffer while audio is playing.
      demuxDecodeWorker.postMessage({command: 'pause'});
    });

    sendMediaTimeUpdates(false);

    playButton.innerText = "Play"
  }
}


//周期性发送当前媒体时间
//这一步操作原本应该放在worker上面进行
//但是由于webaudio自身的限制，所以。。
// Helper function to periodically send the current media time to the media
// worker. Ideally we would instead compute the media time on the worker thread,
// but this requires WebAudio interfaces to be exposed on the WorkerGlobalScope.
// See https://github.com/WebAudio/web-audio-api/issues/2423
let mediaTimeUpdateInterval = null;
function sendMediaTimeUpdates(enabled) {
  if (enabled) {
    // Local testing shows this interval (1 second) is frequent enough that the
    // estimated media time between updates drifts by less than 20 msec. Lower
    // values didn't produce meaningfully lower drift and have the downside of
    // waking up the main thread more often. Higher values could make av sync
    // glitches more noticeable when changing the output device.
    //1秒钟的间隔已经足够了
    const UPDATE_INTERVAL = 1000;
    mediaTimeUpdateInterval = setInterval(() => {
      //每一秒钟，主线程向worker发送一个信息，type为update-media-time
      demuxDecodeWorker.postMessage({
          command: 'update-media-time',
          mediaTimeSecs: myAudioContext.getMediaTimeInSeconds(),
          mediaTimeCapturedAtHighResTimestamp:
              performance.now() + performance.timeOrigin
      });
    }, UPDATE_INTERVAL);
  } else {
    //如果enabled为false，那么清除这个定时函数
    clearInterval(mediaTimeUpdateInterval);
    mediaTimeUpdateInterval = null;
  }
}
</script>

</html>

